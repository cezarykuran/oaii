% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/api_completions.R
\name{completions_create_request}
\alias{completions_create_request}
\title{API completions: create request}
\usage{
completions_create_request(
  api_key,
  prompt,
  model = "gpt-3.5-turbo",
  suffix = NULL,
  max_tokens = 50,
  temperature = 0.7,
  n = 1,
  echo = FALSE,
  presence_penalty = 0,
  frequency_penalty = 0
)
}
\arguments{
\item{api_key}{string, API key}

\item{prompt}{API endpoint parameter}

\item{model}{string, ID of the model to use. You can use the
\href{https://platform.openai.com/docs/api-reference/models/list}{List models}
API to see all of your available models, or see our
\href{https://platform.openai.com/docs/models/overview}{Model overview}
for descriptions of them.API endpoint parameter}

\item{suffix}{string/NULL, the suffix that comes after a completion
of inserted text.}

\item{max_tokens}{integer, the maximum number of
\href{https://platform.openai.com/tokenizer}{tokens} to generate
in the completion. The token count of your prompt plus max_tokens cannot
exceed the model's context length.}

\item{temperature}{double, what sampling temperature to use, between 0 and 2.
Higher values like 0.8 will make the output more random,
while lower values like 0.2 will make it more focused and deterministic.}

\item{n}{integer, How many completions to generate for each prompt.
Note: Because this parameter generates many completions,
it can quickly consume your token quota. Use carefully
and ensure that you have reasonable settings for `max_tokens` and `stop`.}

\item{echo}{logical, echo back the prompt in addition to the completion}

\item{presence_penalty}{double, Number between -2.0 and 2.0.
Positive values penalize new tokens based on whether they appear in the text
so far, increasing the model's likelihood to talk about new topics.}

\item{frequency_penalty}{double, Number between -2.0 and 2.0.
Positive values penalize new tokens based on their existing frequency
in the text so far, decreasing the model's likelihood to repeat the same line
verbatim.}
}
\value{
content of the httr response object or SimpleError
}
\description{
\url{https://platform.openai.com/docs/api-reference/completions/create}
}
