% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/api_chat.R
\name{feedback}
\alias{feedback}
\title{Feedback - ask chat and receive reply}
\usage{
feedback(question, model = "gpt-3.5-turbo", max_tokens = NULL, print = TRUE)
}
\arguments{
\item{question}{string, question text}

\item{model}{string, ID of the model to use. See the model endpoint compatibility table
https://platform.openai.com/docs/models/model-endpoint-compatibility
for details on which models work with the Chat API.}

\item{max_tokens}{NULL/int, the maximum number of tokens to generate in the chat completion}

\item{print}{flag, If TRUE, print the answer on the console}
}
\value{
string, chat answer
}
\description{
Simple \link{chat_request} wrapper - send text to chat and get response.
}
